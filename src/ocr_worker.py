# src/ocr_worker.py
# Background thread that processes images through the OCR AI model.
# Handles streaming output and parses grounding tags for bounding boxes.

import time
import re
import ast
from PySide6.QtCore import QThread, Signal
from ollama_service import stream_ocr_response
import file_handler
import config


class OCRWorker(QThread):
    """
    Worker thread that processes a queue of images through DeepSeek-OCR.

    Signals (events emitted to notify the main UI thread):
    - stream_chunk: Emits text as it's generated by DeepSeek-OCR
    - image_started: Emits when starting to process a new image
    - image_finished: Emits when done with an image (includes duration)
    - finished_all: Emits when entire queue is processed
    - error_occurred: Emits error messages
    - box_detected: Emits bounding box coordinates [x1, y1, x2, y2]
    """
    stream_chunk = Signal(str)
    image_started = Signal(str, int)
    image_finished = Signal(str, float)
    finished_all = Signal()
    error_occurred = Signal(str)
    box_detected = Signal(list)

    def __init__(self, client, queue_items, prompt, model_name, prompt_id=None):
        super().__init__()
        self.client = client
        self.queue_items = queue_items 
        self.prompt = prompt
        self.model_name = model_name
        self.prompt_id = prompt_id
        self.is_running = True 

        """
        Grounding mode determines how to handle grounding tags:
        - 'markdown': Suppress <|ref|> content (useless metadata)
        - 'ocr': Emit <|ref|> content (it contains actual OCR text)
        - None: Passthrough mode, no tag processing
        """
        if prompt_id == 'p_markdown':
            self.grounding_mode = 'markdown'
        elif prompt_id == 'p_ocr':
            self.grounding_mode = 'ocr'
        else:
            self.grounding_mode = None

        # Regex pattern for parsing paired grounding tags from AI output
        # See: https://deepwiki.com/deepseek-ai/DeepSeek-OCR/3.5-understanding-output#tag-detection-pattern
        # Expects: <|ref|>LABEL<|/ref|><|det|>COORDINATES<|/det|>
        self.pattern_pair = re.compile(r"(<\|ref\|>(.*?)<\|/ref\|>\s*<\|det\|>(.*?)<\|/det\|>)", re.DOTALL)

        self.buffer = ""  # Accumulates streamed text for tag parsing
        self.pending_backspace = False

    def run(self):
        # Main thread execution - processes each image in the queue
        try:
            for i, (display_name, filepath, page_index) in enumerate(self.queue_items):
                if not self.is_running: break 

                self.image_started.emit(display_name, i)

                start_time = time.time()
                try:
                    if page_index == -1:
                        # Regular image file
                        img_bytes = file_handler.get_image_bytes(filepath)
                    elif page_index == -2: 
                        # Clipboard image, (filepath is actually the image bytes) no need to convert
                        img_bytes = filepath
                    else:
                        # PDF page (page_index is 0-based)
                        img_bytes = file_handler.extract_pdf_page_bytes(filepath, page_index)
                except Exception as e:
                    self.error_occurred.emit(f"Failed to load {display_name}: {e}")
                    continue

                # Process each chunk from the streaming AI response
                self.buffer = ""
                for chunk in stream_ocr_response(self.client, self.model_name, self.prompt, img_bytes, config.INFERENCE_PARAMS):
                    if not self.is_running: break 
                    self.process_chunk(chunk)

                # Flush any remaining text in buffer
                if self.buffer:
                    self.stream_chunk.emit(self.buffer)
                    self.buffer = ""

                duration = time.time() - start_time

                # Explicitly delete image bytes to free RAM immediately
                del img_bytes 

                if not self.is_running: break
                self.image_finished.emit(display_name, duration)

            self.finished_all.emit()

        except Exception as e:
            self.error_occurred.emit(str(e))

    def process_chunk(self, chunk):
        """
        Processes a chunk of streaming text from the AI.
        In passthrough mode: directly emits all text.
        In grounding mode: parses paired <|ref|>...<|/ref|><|det|>...<|/det|> tags,
        extracting bounding boxes and filtering output based on mode.
        """
        # Passthrough mode: no grounding tags expected, emit directly
        if self.grounding_mode is None:
            self.stream_chunk.emit(chunk)
            return

        # Handle pending backspace from previous chunk
        if self.pending_backspace and chunk:
            while chunk and chunk[0].isspace():
                chunk = chunk[1:]

            if not chunk:
                # Chunk was all whitespace, wait for next one
                self.pending_backspace = True
            else:
                self.pending_backspace = False

        self.buffer += chunk

        # Loop to process all complete tag pairs in buffer
        while True:
            match = self.pattern_pair.search(self.buffer)
            if not match:
                break

            full_match = match.group(1)
            ref_content = match.group(2)
            det_content = match.group(3)

            start, end = match.span()

            # Emit any text that appears before the tag
            prefix = self.buffer[:start]
            if prefix:
                self.stream_chunk.emit(prefix)

            # --- Process the REF part ---
            # In 'ocr' mode, ref tags contain the actual OCR text - emit it
            if self.grounding_mode == 'ocr' and ref_content:
                self.stream_chunk.emit(ref_content)

            # Use 'grounding_mode' logic to decide on suppression
            # If 'markdown' mode, we suppress the label entirely.
            # If 'ocr' mode, we emitted it above.

            # --- Process the DET part ---
            try:
                # Format can be [[x,y,x,y]] or [[x,y,x,y], [x,y,x,y]]
                parsed_data = ast.literal_eval(det_content)

                # Case 1: Single box [x1, y1, x2, y2]
                if len(parsed_data) == 4 and all(isinstance(x, (int, float)) for x in parsed_data):
                    self.box_detected.emit(parsed_data)

                # Case 2: Multiple boxes [[x1, y1...], [x2, y2...]]
                else:
                    for item in parsed_data:
                        if isinstance(item, list) and len(item) == 4:
                            self.box_detected.emit(item)
            except Exception:
                pass  # Invalid coordinates, ignore

            # Determine if we should consume following whitespace
            # In 'markdown' mode, we consume whitespace to clean up the removal of tags.
            # In 'ocr' mode, we MUST preserve whitespace (newlines, spaces) as it represents document structure.
            if self.grounding_mode == 'markdown':
                while end < len(self.buffer) and self.buffer[end].isspace():
                    end += 1

                if end == len(self.buffer):
                    self.pending_backspace = True

            # Remove processed tag from buffer
            self.buffer = self.buffer[end:]

        # === Buffer flushing logic ===
        # We need to be careful not to emit partial tags
        # The start of the sequence is "<|ref|>"
        # We also need to be careful about not emitting the start of a tag

        MAX_BUFFER_SIZE = 1000
        LAST_POSSIBLE_START_LEN = 20 # Enough to cover <|ref|> and a bit more

        # If buffer is very small, it might be the start of a tag.
        # But specifically, we only care if it ends with a partial "<..." sequence.

        if "<|ref|>" in self.buffer:
            # We have a start tag, but regex didn't match (so it's an incomplete pair).
            # We must hold everything from the start tag onwards.
            start_idx = self.buffer.find("<|ref|>")

            safe_part = self.buffer[:start_idx]
            if safe_part:
                self.stream_chunk.emit(safe_part)
                self.buffer = self.buffer[start_idx:]

            # Emergency flush if buffer gets too large
            if len(self.buffer) > MAX_BUFFER_SIZE:
                self.stream_chunk.emit(self.buffer)
                self.buffer = ""
            return

        last_open_angle = self.buffer.rfind("<")

        if last_open_angle == -1:
            # No '<' found - safe to emit entire buffer
            self.stream_chunk.emit(self.buffer)
            self.buffer = ""
        else:
            tail = self.buffer[last_open_angle:]

            # Check if this tail could be the start of <|ref|>
            tag_start = "<|ref|>"

            is_dangerous = False

            # Case 1: tail is a prefix of tag_start (e.g. "<", "<|", "<|r")
            if tag_start.startswith(tail):
                is_dangerous = True

            # Case 2: tail starts with tag_start (covered by earlier check, but kept for logic)
            # Since we checked 'if "<|ref|>" in self.buffer' above, and returned, 
            # we know tail does NOT contain "<|ref|>".
            # So tail cannot start with tag_start.

            if is_dangerous:
                # Keep the tail in buffer, emit everything before it
                safe_part = self.buffer[:last_open_angle]
                if safe_part:
                    self.stream_chunk.emit(safe_part)
                self.buffer = tail
            else:
                # No partial start tag. Safe to emit.
                self.stream_chunk.emit(self.buffer)
                self.buffer = ""

            # Emergency flush handled above for the ref case, but good to keep
            if len(self.buffer) > MAX_BUFFER_SIZE:
                self.stream_chunk.emit(self.buffer)
                self.buffer = ""

    def stop(self):
        # Request the worker to stop processing (checked between images)
        self.is_running = False
